# ğŸ¥ YouTube Video Q&A App using Streamlit, LangChain & Groq (RAG-based)

This is a **Retrieval-Augmented Generation (RAG)** based Streamlit app that allows users to:
- Enter a **YouTube video ID**
- Automatically fetch the **transcript**
- Ask **natural language questions**
- Get accurate answers from an LLM based **only on the video content**
---

## ğŸš€ Features

- ğŸ” Accepts **YouTube video IDs**
- ğŸŒ Works with **manual and auto-generated captions**, in **any language**
- ğŸ“œ Automatically fetches and processes the **video transcript**
- ğŸ§  Uses **HuggingFace embeddings** for semantic search
- ğŸ§® Stores transcript vectors using **FAISS**
- ğŸ¤– Answers generated by **Groq LLaMA 3** via **LangChain**
- ğŸ’¬ Ask **natural language questions** about the video
- ğŸ›ï¸ Clean and interactive **two-page Streamlit interface**
- ğŸ”— **Clickable link** to open the YouTube video directly
- ğŸ”™ Includes a **Back to Home** button for seamless navigation
- âœ… Context-limited QA: prevents hallucinations by answering only from the transcript
- âš¡ Fast response thanks to **Groq's high-speed LLaMA inference**



---

## ğŸ§° Tech Stack

| Component                     | Description                                   |
|------------------------------|-----------------------------------------------|
| [Streamlit](https://streamlit.io/)        | UI and interaction                          |
| [LangChain](https://www.langchain.com/)   | RAG pipeline + LLM + prompt templating      |
| [Groq API](https://console.groq.com/)     | LLM provider (LLaMA3)                        |
| [YouTubeTranscriptAPI](https://pypi.org/project/youtube-transcript-api/) | Fetches subtitles from YouTube              |
| [FAISS](https://github.com/facebookresearch/faiss)       | Fast vector similarity search                |
| [HuggingFace Embeddings](https://huggingface.co/sentence-transformers) | Converts text into semantic vector space     |

---
## ğŸ–¥ï¸ How It Works

1. User inputs a **YouTube video ID** (e.g., `rkKsMkOi3q4`)
2. The app fetches the **transcript** using `YouTubeTranscriptAPI`
3. Transcript is **chunked** into 1000-character blocks
4. Each chunk is embedded using `sentence-transformers/all-MiniLM-L6-v2`
5. Vector store is created with **FAISS**
6. User asks a question â top-k similar transcript chunks are retrieved
7. These chunks + question are sent to **Groqâ€™s LLaMA3 model** via LangChain
8. Answer is returned and displayed in the UI

---
## ğŸ“¸ Demo Screenshots

### ğŸ–¼ï¸ App Preview

![Screenshot 1](Screenshot%20(1371).png)
![Screenshot 2](Screenshot%20(1372).png)
![Screenshot 3](Screenshot%20(1373).png)
![Screenshot 4](Screenshot%20(1374).png)
![Screenshot 5](Screenshot%20(1375).png)
